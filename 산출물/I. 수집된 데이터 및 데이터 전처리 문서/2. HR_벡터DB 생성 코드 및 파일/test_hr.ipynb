{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가\n",
    "1. 인사정보 평가\n",
    "    - 임베딩 모델 : KURE-V1\n",
    "    - 리랭크 모델 : BGE-RERANKER-KO\n",
    "    - 질문지 : GPT-4O 생성 102개질문지\n",
    "    - LLM : GPT-4O-mini\n",
    "    - topk1~5 측정\n",
    "\n",
    "2. 평가 결과\n",
    "    - topk 1~5 F1/EM score : 41.11/34.04 46.52/37.77 48.09/38.30 46.62/38.30 48.59/39.36\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdy\\AppData\\Local\\Temp\\ipykernel_29600\\794522863.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 및 환경설정\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import evaluate\n",
    "\n",
    "client = OpenAI(api_key=\"key\")  \n",
    "\n",
    "# 임베딩모델 로드 ( 허깅페이스 )\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"work1/models/kure_v1\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 [실험] Top-1 문서 → 리랭커 → GPT 응답 평가\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:03<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 F1: 41.11\n",
      "📊 평균 EM: 34.04\n",
      "\n",
      "🔍 [실험] Top-2 문서 → 리랭커 → GPT 응답 평가\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [02:34<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 F1: 46.52\n",
      "📊 평균 EM: 37.77\n",
      "\n",
      "🔍 [실험] Top-3 문서 → 리랭커 → GPT 응답 평가\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [03:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 F1: 48.09\n",
      "📊 평균 EM: 38.30\n",
      "\n",
      "🔍 [실험] Top-4 문서 → 리랭커 → GPT 응답 평가\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [06:20<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 F1: 46.62\n",
      "📊 평균 EM: 38.30\n",
      "\n",
      "🔍 [실험] Top-5 문서 → 리랭커 → GPT 응답 평가\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [08:08<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 F1: 48.59\n",
      "📊 평균 EM: 39.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 내부 규정 평가 - 리랭커 top-k 실험\n",
    "\n",
    "from rag_eval import run_custom_prompt_eval_group\n",
    "\n",
    "my_custom_prompt = (\n",
    "    \"\"\"질문에 정확히 대응하는 정답만 말하세요. 예시:\n",
    "Q: 퇴직금은 어떻게 계산되나요? → 평균임금\n",
    "Q: 지급 대상은 누구인가요? → 퇴직자\n",
    "이와 같은 방식으로 단답형 정답만 출력하세요. 정답이 없으면 '문서에 없습니다'라고 하세요.\"\"\"\n",
    ")\n",
    "\n",
    "# ✅ Top-k 실험 루프\n",
    "for k in range(1, 6):  # top_k=1~5\n",
    "    print(f\"\\n🔍 [실험] Top-{k} 문서 → 리랭커 → GPT 응답 평가\")\n",
    "    run_custom_prompt_eval_group(\n",
    "        client=client,\n",
    "        embedding=embedding,\n",
    "        eval_path=\"eval_questions_gpt.jsonl\",\n",
    "        top_k=k,\n",
    "        system_prompt=my_custom_prompt\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
