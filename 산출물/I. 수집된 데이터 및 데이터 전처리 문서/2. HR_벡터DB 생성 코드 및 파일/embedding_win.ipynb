{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector DB 구축 \n",
    "1. 데이터 확인 - 텍스트,자연어,테이블데이터 혼합형 / 코드확인 및 수동으로 확인 \n",
    "2. 데이터 전처리 및 기본 청크 진행 \n",
    "3. 청크 확인 \n",
    "4. 청크 보완작업 ( 슬라이딩 윈도우 방식 ) \n",
    "5. 임베딩 (kure-v1 / faiss db) \n",
    "6. 질문지 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 문단 수: 223\n",
      "00: 'DM_solution 사내규정'\n",
      "01: ''\n",
      "02: '목차'\n",
      "03: '출장 및 여비규정'\n",
      "04: '퇴직금 지급 및 퇴직 규정'\n",
      "05: '복리후생 규정'\n",
      "06: '복무 규정'\n",
      "07: '급여 규정'\n",
      "08: '업무 규정'\n",
      "09: '정보보안 규정)'\n",
      "10: '윤리 및 행동강령'\n",
      "11: '사내 여비규정 (출장규정)'\n",
      "12: '제1장 총 칙'\n",
      "13: '제1조【목적】\n",
      "이 규정은 직원의 국내 및 해외 출장에 따른 여비 지급 및 처리 기준을 정함으로써, 경비의 합리적 지출과 출장업무의 원활한 수행을 도모하는 것을 목적으로 한다.'\n",
      "14: '제2조【적용범위】\n",
      "이 규정은 본사 및 국내·해외 지사 소속 전 직원에게 적용한다. 단, 계약직 및 인턴사원은 별도의 승인 없이 출장할 수 없다.'\n",
      "15: '제3조【정의】\n",
      "이 규정에서 “출장”이라 함은 회사의 업무를 수행하기 위하여 본래 근무지를 떠나 일시적으로 다른 지역에 체류하는 것을 말한다.'\n",
      "16: ''\n",
      "17: '제2장 출장 승인 및 신청'\n",
      "18: '제4조【출장 승인】\n",
      "모든 출장은 사전에 소속 부서장과 경영지원팀의 승인을 받아야 하며, 승인된 출장만 여비가 지급된다.'\n",
      "19: '제5조【출장 신청 절차】\n",
      "① 출장신청서는 출장 3일 전까지 시스템에 등록해야 한다.\n",
      "② 해외출장의 경우, 별도의 사전보고서와 현지 연락처가 포함된 계획서를 첨부해야 한다.'\n",
      "20: ''\n",
      "21: '제3장 여비의 종류 및 기준'\n",
      "22: '제6조【여비 구성 항목】\n",
      "여비는 다음 각 항목으로 구성한다.'\n",
      "23: '교통비'\n",
      "24: '일비(숙박 외 체재비)'\n",
      "25: '숙박비'\n",
      "26: '식비'\n",
      "27: '통신비 및 잡비(필요 시 인정)'\n",
      "28: '제7조【교통비 지급 기준】\n",
      "① 국내 출장 시에는 대중교통을 원칙으로 한다.\n",
      "② 자가용 사용 시 사전 승인과 주행거리 증빙자료(네비게이션 캡처 등)를 첨부해야 한다.\n",
      "③ 해외출장 시에는 이코노미 클래스만 이용가능하다. 사업 목적의 동반자가 있을 경우에는 퍼스트 클래스 이용이 가능하다. ( CEO포함 전 직원 공통 )'\n",
      "29: '제8조【숙박비 지급 기준】\n",
      "① 국내 출장: 1박당 100,000원 이내 실비 정산\n",
      "② 해외 출장: 국가별 상한선을 두며, 외교부 공무 출장 기준을 참고한다.\n",
      "③ 단, 호텔 이용 시 반드시 카드 영수증과 호텔 명세서를 제출해야 한다.'\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 확인\n",
    "\n",
    "from docx import Document\n",
    "from pathlib import Path\n",
    "\n",
    "# 📂 파일 경로 설정\n",
    "file_path = Path(\"work1/data/DM_rules.docx\").resolve()\n",
    "\n",
    "# 📄 문서 불러오기\n",
    "doc = Document(file_path)\n",
    "\n",
    "# 📑 전체 문단 확인\n",
    "print(f\"✅ 총 문단 수: {len(doc.paragraphs)}\")\n",
    "\n",
    "# 🔍 앞부분 30개 문단 미리보기\n",
    "for i, para in enumerate(doc.paragraphs[:30]):\n",
    "    print(f\"{i:02d}: '{para.text.strip()}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 요소 수 (문단+표 포함): 182\n",
      "✅ 생성된 청크 수: 42\n",
      "📁 저장 완료: dm_chunks.json\n"
     ]
    }
   ],
   "source": [
    "# 2. 데이터 전처리 및 기본 청크 진행\n",
    "\n",
    "from docx import Document\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from uuid import uuid4\n",
    "\n",
    "# 1. 경로 설정\n",
    "docx_path = Path(\"work1/data/DM_rules.docx\")  # 실제 전체 문서\n",
    "output_path = Path(\"work1/data/dm_chunks.json\")\n",
    "\n",
    "# 2. 문서 로드\n",
    "doc = Document(docx_path)\n",
    "\n",
    "# 3. 문단 + 표 포함 전체 텍스트 수집\n",
    "elements = []\n",
    "\n",
    "# 문단 추가\n",
    "for para in doc.paragraphs:\n",
    "    text = para.text.strip()\n",
    "    if text:\n",
    "        elements.append(text)\n",
    "\n",
    "# 표 추출\n",
    "for table in doc.tables:\n",
    "    table_text = []\n",
    "    for row in table.rows:\n",
    "        cells = [cell.text.strip() for cell in row.cells]\n",
    "        table_text.append(\" | \".join(cells))\n",
    "    elements.append(\"\\n\".join(table_text))\n",
    "\n",
    "# 4. 조문 기준 전처리\n",
    "chunks = []\n",
    "current_title = \"\"\n",
    "current_body = []\n",
    "\n",
    "for line in elements:\n",
    "    if re.match(r\"^제\\d+조[【\\[ ].*?[】\\]]\", line):  # 새로운 조문 시작\n",
    "        if current_title and current_body:\n",
    "            chunks.append({\n",
    "                \"text\": \"\\n\".join(current_body),\n",
    "                \"metadata\": {\n",
    "                    \"section\": current_title,\n",
    "                    \"chunk_id\": f\"{current_title}_{str(uuid4())[:8]}\"\n",
    "                }\n",
    "            })\n",
    "        current_title = line\n",
    "        current_body = []\n",
    "    else:\n",
    "        current_body.append(line)\n",
    "\n",
    "# 마지막 청크 추가\n",
    "if current_title and current_body:\n",
    "    chunks.append({\n",
    "        \"text\": \"\\n\".join(current_body),\n",
    "        \"metadata\": {\n",
    "            \"section\": current_title,\n",
    "            \"chunk_id\": f\"{current_title}_{str(uuid4())[:8]}\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "# 5. 저장\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 6. 통계 출력\n",
    "print(f\"✅ 총 요소 수 (문단+표 포함): {len(elements)}\")\n",
    "print(f\"✅ 생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"📁 저장 완료: {output_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 청크 수: 42\n",
      "❌ 중복 chunk_id 수: 0\n",
      "📏 평균 길이: 38자\n",
      "📏 최대 길이: 515 / 최소 길이: 8\n",
      "\n",
      "📚 조문 형식 만족 청크 수: 42\n",
      "✅ 모든 청크가 조문 형식을 만족합니다.\n"
     ]
    }
   ],
   "source": [
    "# 3. 청크 확인 \n",
    "\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# 파일 로드\n",
    "with open(\"work1/data/dm_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "# 중복 ID 체크\n",
    "ids = [chunk[\"metadata\"][\"chunk_id\"] for chunk in chunks]\n",
    "dup_ids = [item for item, count in Counter(ids).items() if count > 1]\n",
    "\n",
    "# 길이 통계\n",
    "lengths = [len(chunk[\"text\"]) for chunk in chunks]\n",
    "avg_len = sum(lengths) // len(lengths)\n",
    "min_len = min(lengths)\n",
    "max_len = max(lengths)\n",
    "\n",
    "# 조문 형식 체크\n",
    "pattern = r\"제\\d+조[【\\[ ].*?[】\\]]\"\n",
    "valid_titles = [chunk[\"metadata\"][\"section\"] for chunk in chunks if re.search(pattern, chunk[\"metadata\"][\"section\"])]\n",
    "invalid_titles = [chunk[\"metadata\"][\"section\"] for chunk in chunks if not re.search(pattern, chunk[\"metadata\"][\"section\"])]\n",
    "\n",
    "# 출력\n",
    "print(f\"✅ 총 청크 수: {len(chunks)}\")\n",
    "print(f\"❌ 중복 chunk_id 수: {len(dup_ids)}\")\n",
    "print(f\"📏 평균 길이: {avg_len}자\")\n",
    "print(f\"📏 최대 길이: {max_len} / 최소 길이: {min_len}\\n\")\n",
    "\n",
    "print(f\"📚 조문 형식 만족 청크 수: {len(valid_titles)}\")\n",
    "if invalid_titles:\n",
    "    print(f\"⚠️ 형식 불만족 청크 예시: {invalid_titles[:3]}\")\n",
    "else:\n",
    "    print(\"✅ 모든 청크가 조문 형식을 만족합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 생성 완료: 총 88개\n",
      "📏 평균 길이: 303자\n",
      "📏 최대 길이: 527 / 최소 길이: 180\n"
     ]
    }
   ],
   "source": [
    "# 4. 청크 보완작업 ( 슬라이딩 윈도우 방식 ) \n",
    "\n",
    "import json\n",
    "\n",
    "# 1. 기존 청크 로드\n",
    "with open(\"dm_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "# 2. 슬라이딩 윈도우 병합\n",
    "WINDOW_SIZE = 3\n",
    "STRIDE = 1\n",
    "windowed_chunks = []\n",
    "\n",
    "for i in range(0, len(chunks) - WINDOW_SIZE + 1, STRIDE):\n",
    "    group = chunks[i:i + WINDOW_SIZE]\n",
    "    combined_text = \"\\n\".join([c[\"text\"] for c in group])\n",
    "    section = group[0][\"metadata\"][\"section\"]  \n",
    "    chunk_id = f\"{section}_win_{i+1}\"\n",
    "\n",
    "    windowed_chunks.append({\n",
    "        \"text\": combined_text,\n",
    "        \"metadata\": {\n",
    "            \"section\": section,\n",
    "            \"chunk_id\": chunk_id\n",
    "        }\n",
    "    })\n",
    "\n",
    "# 3. 저장\n",
    "with open(\"dm_chunks_window.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(windowed_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 4. 확인\n",
    "lengths = [len(c[\"text\"]) for c in windowed_chunks]\n",
    "print(f\"✅ 생성 완료: 총 {len(windowed_chunks)}개\")\n",
    "print(f\"📏 평균 길이: {sum(lengths)//len(lengths)}자\")\n",
    "print(f\"📏 최대 길이: {max(lengths)} / 최소 길이: {min(lengths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 임베딩 중...\n",
      "✅ 저장 완료: faiss_win\n"
     ]
    }
   ],
   "source": [
    "# 5. 임베딩 ( 청크보완파일 ,kure-v1 , faiss db) \n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 🟦 1. 설정\n",
    "MODEL_NAME = \"work1\\models\\kure_v1\"\n",
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 32\n",
    "DATA_FILE = \"dm_chunks_window.json\"  \n",
    "INDEX_DIR = \"faiss_win\"  \n",
    "\n",
    "# 🟦 2. JSON 로드\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=item[\"text\"],\n",
    "        metadata=item[\"metadata\"]\n",
    "    ) for item in data\n",
    "]\n",
    "\n",
    "# 🟦 3. 임베딩 모델 로드\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_kwargs={\"device\": DEVICE},\n",
    "    encode_kwargs={\"normalize_embeddings\": True, \"batch_size\": BATCH_SIZE}\n",
    ")\n",
    "\n",
    "# 🟦 4. 임베딩 + 저장\n",
    "print(\"⏳ 임베딩 중...\")\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "vectorstore.save_local(INDEX_DIR)\n",
    "print(f\"✅ 저장 완료: {INDEX_DIR}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [01:54<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 총 132개 문항 → eval_questions.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. 평가를 위한 질문지 생성 ( openai gpt-4o )\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = OpenAI(api_key=\"Key\")\n",
    "                \n",
    "# 1. 청크 로드\n",
    "with open(\"dm_chunks_merged.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "questions = []\n",
    "\n",
    "# 2. 고품질 질문 유도 프롬프트 생성 + 요청\n",
    "for chunk in tqdm(chunks):\n",
    "    prompt = f\"\"\"\n",
    "다음은 사내 규정의 한 조문입니다. 여기에 기반하여 실제 직원들이 물어볼 수 있는 질문을 3개 생성하세요.\n",
    "\n",
    "[규정 내용]\n",
    "\\\"\\\"\\\"\n",
    "{chunk[\"text\"]}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "조건:\n",
    "- 실제 사용자가 물어볼 법한 질문일 것\n",
    "- 숫자, 조건문, 예외사항이 있다면 반드시 반영할 것\n",
    "- 질문은 한국어로, 자연스러운 말투로 작성\n",
    "- 답변은 반드시 위 텍스트 내에서만 추출 가능해야 함\n",
    "\n",
    "형식:\n",
    "[\n",
    "  {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "  ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        raw = response.choices[0].message.content\n",
    "        qa_list = json.loads(raw)\n",
    "        for qa in qa_list:\n",
    "            if qa[\"question\"].strip() and qa[\"answer\"].strip():\n",
    "                questions.append(qa)\n",
    "    except Exception as e:\n",
    "        print(f\"[⚠️ Error] 청크 ID: {chunk['metadata']['chunk_id']} → {e}\")\n",
    "\n",
    "# 3. 저장\n",
    "with open(\"eval_questions_merged.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for q in questions:\n",
    "        f.write(json.dumps(q, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ 저장 완료: 총 {len(questions)}개 문항 → eval_questions_merged.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 GPT 응답 내용 확인:\n",
      "'[\\n  {\"question\": \"서약서를 제출하지 않으면 어떻게 되나요?\", \"answer\": \"모든 임직원은 본 강령을 숙지하고 서약서를 제출해야 하며, 위반 시 책임을 진다.\"},\\n  {\"question\": \"서약서는 얼마나 오랫동안 보관되나요?\", \"answer\": \"서약서는 인사기록과 함께 3년간 보관된다.\"},\\n  {\"question\": \"서약서를 제출해야 하는 사람은 누구인가요?\", \"answer\": \"모든 임직원은 본 강령을 숙지하고 서약서를 제출해야 한다.\"}\\n]'\n"
     ]
    }
   ],
   "source": [
    "# 질문지 결과 확인\n",
    "\n",
    "print(\"📤 GPT 응답 내용 확인:\")\n",
    "print(repr(response.choices[0].message.content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
