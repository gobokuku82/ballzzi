{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가\n",
    "1. 내부규정 평가\n",
    "    - 청크보완 방식 : 슬라이딩 윈도우 방식\n",
    "    - 임베딩 모델 : KURE-V1\n",
    "    - 리랭크 모델 : BGE-RERANKER-KO\n",
    "    - 질문지 : GPT-4O 생성 132개질문지\n",
    "    - LLM : GPT-4O-mini\n",
    "    - 프롬프트 5종에 따른 점수평가\n",
    "2. 평가 결과\n",
    "    - 청크보완임베딩 + gpt - f1/em  : 40.4433/0.000040\n",
    "    - 청크보완임베딩 + gpt + 리랭커 + 금지형 프롬프트 - f1/em : 55.04/10.61\n",
    "    - 청크보완임베딩 + gpt + 리랭커 + 4가지 프롬프트 - f1/em \n",
    "      : 43.17/0.76 47.58/6.82 46.91/0.00 14.6/00.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kdy\\anaconda3\\envs\\llm3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\kdy\\AppData\\Local\\Temp\\ipykernel_23076\\794522863.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 및 환경설정\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import evaluate\n",
    "\n",
    "client = OpenAI(api_key=\"Key\")  \n",
    "\n",
    "# 임베딩모델 로드 ( 허깅페이스 )\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"work1/models/kure_v1\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 F1 평균: 40.4433\n",
      "📊 EM 평균: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 1. 청크보완임베딩 + gpt - f1/em  : 40.4433/0.000040\n",
    "\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import evaluate\n",
    "\n",
    "# 1. 임베딩 모델 로드\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"work1/models/kure_v1\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "# 2. FAISS 벡터 DB 로드\n",
    "vectorstore = FAISS.load_local(\n",
    "    folder_path=\"faiss_win\",\n",
    "    embeddings=embedding,\n",
    "    index_name=\"index\",\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 3. 평가 질문지 로드\n",
    "with open(\"eval_questions_window.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_pairs = [json.loads(line) for line in f]\n",
    "\n",
    "# 4. GPT-4o 호출 함수 (순차 처리, Top-k=1)\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# GPT-4o 호출 함수 (동기 버전)\n",
    "def ask(question, context):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 회사 규정에 대해 정확하게 답변하는 도우미입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"다음은 관련 문서입니다:\\n{context}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"질문: {question}\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# 전체 실행 루프 (동기 처리)\n",
    "results = []\n",
    "for qa in qa_pairs:\n",
    "    docs = vectorstore.similarity_search(qa[\"question\"], k=1)\n",
    "    context = docs[0].page_content if docs else \"\"\n",
    "    gen = ask(qa[\"question\"], context)\n",
    "    results.append(gen)\n",
    "\n",
    "\n",
    "# 5. SQuAD 평가\n",
    "squad = evaluate.load(\"squad\")\n",
    "predictions = [{\"id\": str(i), \"prediction_text\": gen} for i, gen in enumerate(results)]\n",
    "references = [{\"id\": str(i), \"answers\": {\"text\": [qa[\"answer\"]], \"answer_start\": [0]}} for i, qa in enumerate(qa_pairs)]\n",
    "\n",
    "score = squad.compute(predictions=predictions, references=references)\n",
    "print(f\"📊 F1 평균: {score['f1']:.4f}\")\n",
    "print(f\"📊 EM 평균: {score['exact_match']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [08:21<00:00,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 F1: 55.04\n",
      "📊 평균 EM: 10.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 청크보완임베딩 + gpt + 리랭커 + 금지형 프롬프트 - f1/em : 55.04/10.61\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from evaluate import load\n",
    "from openai import OpenAI\n",
    "\n",
    "# 🔹 이미 선언된 객체들 (필요시 수정)\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"work1/models/kure_v1\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "# 1. 리랭커 로드 (bge-reranker-v2-m3-ko)\n",
    "reranker = CrossEncoder(\"work1/models/bge-reranker-v2-m3-ko\", device=\"cuda\")\n",
    "\n",
    "# 2. FAISS 벡터DB 로드\n",
    "vectorstore = FAISS.load_local(\n",
    "    folder_path=\"faiss_win\",\n",
    "    embeddings=embedding,\n",
    "    index_name=\"index\",\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 3. 평가 질문 로드\n",
    "with open(\"eval_questions_window.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    eval_questions = [json.loads(line) for line in f]\n",
    "\n",
    "# 4. 평가 지표 준비\n",
    "f1 = load(\"evaluate-metric/squad\", \"f1\")\n",
    "em = load(\"evaluate-metric/squad\", \"exact_match\")\n",
    "\n",
    "f1_scores, em_scores = [], []\n",
    "\n",
    "# 5. 평가 루프\n",
    "for idx, qa in tqdm(enumerate(eval_questions), total=len(eval_questions)):\n",
    "    query = qa[\"question\"]\n",
    "    answer = qa[\"answer\"]\n",
    "    qid = qa.get(\"id\", str(idx))  # ID 없으면 인덱스 사용\n",
    "\n",
    "    # Step 1: Top-5 문서 검색\n",
    "    docs = vectorstore.similarity_search(query, k=5)\n",
    "\n",
    "    # Step 2: reranker로 점수 계산\n",
    "    reranker_inputs = [[query, doc.page_content] for doc in docs]\n",
    "    scores = reranker.predict(reranker_inputs)\n",
    "\n",
    "    # Step 3: 점수 기반 정렬\n",
    "    reranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
    "    top_doc = reranked[0][0].page_content  # 가장 높은 점수 1개 사용\n",
    "\n",
    "    # Step 4: GPT-4o 호출 (프롬프트 개선 포함)\n",
    "    system_prompt = (\n",
    "        \"너는 회사의 사내 규정을 정확히 안내하는 QA 비서야. \"\n",
    "        \"다음 문서의 내용에 기반해서만 답변해. \"\n",
    "        \"문서에 없는 내용은 추론하지 말고 '문서에 없습니다'라고 답변해.\"\n",
    "    )\n",
    "    user_prompt = f\"\"\"문서:\n",
    "{top_doc}\n",
    "\n",
    "질문: {query}\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    prediction = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # Step 5: 평가 포맷 변환 및 F1/EM 계산\n",
    "    prediction_dict = {\"id\": qid, \"prediction_text\": prediction}\n",
    "    reference_dict = {\n",
    "        \"id\": qid,\n",
    "        \"answers\": [{\"text\": answer, \"answer_start\": 0}]\n",
    "    }\n",
    "\n",
    "    f1_score = f1.compute(predictions=[prediction_dict], references=[reference_dict])[\"f1\"]\n",
    "    em_score = em.compute(predictions=[prediction_dict], references=[reference_dict])[\"exact_match\"]\n",
    "\n",
    "    f1_scores.append(f1_score)\n",
    "    em_scores.append(em_score)\n",
    "\n",
    "# 6. 결과 출력\n",
    "print(f\"📊 평균 F1: {sum(f1_scores)/len(f1_scores):.2f}\")\n",
    "print(f\"📊 평균 EM: {sum(em_scores)/len(em_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 실험 프롬프트: basic\n",
      "📊 평균 F1: 43.17\n",
      "📊 평균 EM: 0.76\n",
      "\n",
      "🔍 실험 프롬프트: strict\n",
      "📊 평균 F1: 47.58\n",
      "📊 평균 EM: 6.82\n",
      "\n",
      "🔍 실험 프롬프트: cot\n",
      "📊 평균 F1: 46.91\n",
      "📊 평균 EM: 0.00\n",
      "\n",
      "🔍 실험 프롬프트: step\n",
      "📊 평균 F1: 14.60\n",
      "📊 평균 EM: 0.00\n"
     ]
    }
   ],
   "source": [
    "# 청크보완임베딩 + gpt + 리랭커 + 4가지 프롬프트 - f1/em \n",
    "\n",
    "from rag_eval import run_prompt_ab_test\n",
    "\n",
    "run_prompt_ab_test(\n",
    "    client=client,\n",
    "    embedding=embedding,\n",
    "    prompt_styles=[\"basic\", \"strict\", \"cot\", \"step\"],  # 실험할 프롬프트 종류\n",
    "    top_k=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
